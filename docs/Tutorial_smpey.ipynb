{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paquete SMEPY\n",
    "## Autor: Erik Angulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalación\n",
    "\n",
    "Esta es la guía de uso del paquete 'smer'. Está alojado en \"github.com/erikangulo/smepy\"\n",
    "\n",
    "Este paquete se puede instalar fácilmente a través de la librería devtools, desde Github:\n",
    "\n",
    "También se puede instalar a través del código fuente usando la consola de R.\n",
    "\n",
    "Este paquete tiene dependencias únicamente para ciertas funciones concretas listadas a continuación. El paquete puede operar correctamente sin ellas excepto para las funciones mencionadas e indicará al usuario al ejecutar cada programa si necesita alguna dependencia.\n",
    "\n",
    "* jupyter notebook\n",
    "* pandas\n",
    "* numpy\n",
    "* seaborn\n",
    "* matplotlib\n",
    "\n",
    "Cargamos el paquete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smepy.dataset as ds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso\n",
    "\n",
    "El objetivo de este paquete es facilitar la aplicación de cálculos y estadísticos en datos a usuarios que dispongan de poca experiencia en el ámbito de la programación. También es adecuado para conseguir los resultados deseados automáticamente en pocas líneas de código sin necesidad de programar nada. Entre las funciones disponibles, se encuentran la lectura y escritura de datasets, cálculo de la varianza, curva ROC, discretización, normalización y estandarización de variables, cálculo de la correlación, cálculo de la entropía y distintos gráficos que representen los resultados.\n",
    "\n",
    "En este jupyter notebook presentaremos un tutorial de cómo usar el paquete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestión de Dataset\n",
    "\n",
    "En esta sección observaremos que son los Dataset y como podemos crearlos, cargarlos, guardarlos y visualizarlos.\n",
    "\n",
    "## Creación de Dataset\n",
    "\n",
    "Los Dataset son unas clases que funcionan como tablas, donde cada fila corresponde a instancias y las columnas a las variables. Cada variable será de un tipo, ya sea numérica, lógica o de caracteres. Los dataset, además de la tabla, tendrán un nombre.\n",
    "\n",
    "Empecemos observando como se crea un Dataset.\n",
    "\n",
    "Los Dataset se deben crear con estructura de diccionario, donde las llaves son el nombre de las columnas y los valores son el contenido de las columnas. El único requisito que tiene es que ha de tener como mínimo dos filas y una columna (pues para elementos con una fila independientemente de las columnas ya podemos trabajar con un vector normal y corriente).\n",
    "\n",
    "A cada Dataset le podemos asignar un id o nombre, el cual se generará automáticamente con un número en caso de no especificarlo. Además, podemos decidir si factorizar alguna de sus columnas. De esta forma, aquellas que contengan menos valores distintos que el número indicado serán factorizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre del Dataset: 1\n",
      "Columnas del Dataset: 2\n",
      "Filas del Dataset: 6\n",
      "Contenido del Dataset:\n",
      "   N  L\n",
      "0  3  A\n",
      "1  3  B\n",
      "2  5  D\n",
      "3  8  R\n",
      "4  9  S\n",
      "5  5  P\n"
     ]
    }
   ],
   "source": [
    "prueba1 = [3,3,5,8,9,5]\n",
    "prueba2 = [\"A\", \"B\", \"D\", \"R\", \"S\", \"P\"]\n",
    "dictPrueba = {\"N\" : prueba1, \"L\": prueba2}\n",
    "\n",
    "dsPrueba = ds.Dataset(dictPrueba)\n",
    "print(dsPrueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos cambiarles el nombre a las columnas deseadas o directamente a todas ellas. Para cada columna deseada se indicará mediante un diccionario como llave los nombres antiguos y como valores los nombres nuevos. Para cambiar todas las columnas a la vez basta con crear un array con los nuevos nombres para las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre del Dataset: 1\n",
      "Columnas del Dataset: 2\n",
      "Filas del Dataset: 6\n",
      "Contenido del Dataset:\n",
      "   Num  L\n",
      "0    3  A\n",
      "1    3  B\n",
      "2    5  D\n",
      "3    8  R\n",
      "4    9  S\n",
      "5    5  P\n",
      "Nombre del Dataset: 1\n",
      "Columnas del Dataset: 2\n",
      "Filas del Dataset: 6\n",
      "Contenido del Dataset:\n",
      "   Num Let\n",
      "0    3   A\n",
      "1    3   B\n",
      "2    5   D\n",
      "3    8   R\n",
      "4    9   S\n",
      "5    5   P\n"
     ]
    }
   ],
   "source": [
    "dsPrueba.nombres_columna({\"N\":\"Num\"}) #cambiar la columna deseada\n",
    "print(dsPrueba)\n",
    "dsPrueba.nombres_columna([\"Num\", \"Let\"]) #todas las columnas\n",
    "print(dsPrueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura y guardado de Dataset\n",
    "\n",
    "Además de poder crear Dataset usando los comandos anteriores, también podemos crearlos desde un fichero. De la misma manera, podemos guardar un Dataset como fichero.\n",
    "\n",
    "El guardado de ficheros está limitado a formato csv, pero la lectura puede ser de formato csv o derivados como tsv. Para ello es necesario indicar que separador usa (por defecto \",\") y el caracter usado para los números decimales (por defecto \".\"). De igual manera podemos asignar un nombre al dataset creado. Si el fichero dispone de encabezado, es decir, nombres asignados a cada columna como la primera instancia del fichero, se usarán como nombres del Dataset, en caso contrario, deberá indicarse con el parámetro 'encabezado' como False.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre del Dataset: Puntos\n",
      "Columnas del Dataset: 4\n",
      "Filas del Dataset: 8\n",
      "Contenido del Dataset:\n",
      "   Intento  Puntuacion Participante  Conseguido\n",
      "0        1         2.1         Juan        True\n",
      "1        5         3.4         Pepe       False\n",
      "2        8         5.6        Paula       False\n",
      "3        5         2.3       Marisa        True\n",
      "4        6         8.8        Nerea       False\n",
      "5        4         5.5        Jorge       False\n",
      "6        0         9.6         Juan       False\n",
      "7        0         1.3        Paula        True\n"
     ]
    }
   ],
   "source": [
    "dsPuntos = ds.leer_datos(\"LecturaCSV_R.csv\", nombre=\"Puntos\", encabezado=True, sep=\",\", decimal='.')\n",
    "print(dsPuntos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds.guardar_datos(dsPuntos, \"Guardar.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kisaPy",
   "language": "python",
   "name": "kisapy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
